<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>The Rise of Conversational AI Agents with Large Language Models</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Converted LaTeX to HTML</title>
    <style>
        .scriptsize { font-size: smaller; }
    </style>
</head>


<section class="hero">
<!--    <div class="hero-body">-->
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        The Rise of Conversational AI Agents with Large Language Models
                    </h1>
<!--                    <h3 class="title is-4 conference-authors"><a target="_blank" href="https://arxiv.org/abs/2311.01378">Arxiv Preprint</a></h3>-->
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a target="_blank" href="https://emrecanacikgoz.github.io/">Emre Can Acikgoz</a><sup>1,2</sup>,
                <a target="_blank" href="">Dilek Hakkani-Tur</a><sup>1,2</sup>,
                <a target="_blank" href="">Gokhan Tur</a><sup>1,2</sup>
            </span>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>ConvAI UIUC </span>
                        <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign </span>
                    </div>

                    <div class="column has-text-centered">
                        <span class="author-block">
                            <a href="mailto:acikgoz2@illinois.edu">mail</a></span>
                    </div>
                    <br>
                    <img src="./assets/images/history.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 90%;"/>
                    <br>
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- TODO PDF Link. -->
                <span class="link-block">
                <a target="_blank" href="https://arxiv.org/abs/2405.04685"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>paper</span>
                </a>
              </span>
                            <!-- Code Link. -->
                <span class="link-block">
                <a target="_blank" href="https://github.com/emrecanacikgoz/turkish-llm"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>

                        </div>

                    </div>
                </div>
            </div>
        </div>
<!--    </div>-->
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <div class="content has-text-justified">
                    <p style="font-size: 125%">
                        Large Language Models (LLMs) have brought significant advancements in Natural Language Processing, transforming our interactions with AI by enhancing understanding, reasoning, and task-solving. Traditionally, task-oriented dialogue (TOD) systems guided AI-based assistants to perform predefined tasks by following a structured flow. But with LLMs' ability to understand complex language, interpret instructions, and generate sophisticated responses, we're moving towards a new breed of AI—Conversational AI Agents—that engage users in more dynamic, context-rich conversations and adapt to complex environments. This blogpost discusss the evolution of Conversational Agents in the era of Large Language Models, exploring the challenges, opportunities, and motivates for future directions in this domain.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!--Model-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span class="dvima">LLM-oriented Domain Shift</span></h2>
            <span style="font-size: 100%">
                The backbone of the LLM-based domain shift lies in large-scale self-supervision, where LLMs are trained on vast datasets using transformer-based architectures. These models, like GPT-3, use a method called "self-attention" to process language contextually, which, paired with advances in GPU technology, has enabled LLMs to handle increasingly larger models and datasets. <br> <br>
                A significant leap for LLMs was their ability to follow complex instructions. Instruction tuning teaches LLMs to handle specific prompts better and reason through instructions rather than merely generating text. This process, enhanced with human feedback, aligns LLM responses more closely with user preferences, improving their relevance and clarity. Models like ChatGPT fine-tune instructions with prompts crafted to mirror real-life tasks, enabling more meaningful and accurate conversations. <br> <br>
                Introduced with models like GPT-3, in-context learning allows LLMs to learn from a few examples provided within the conversation itself. This technique eliminates the need for retraining, enabling models to adapt quickly. Furthermore, advanced methods like Chain-of-Thought (CoT) prompting have been developed, allowing LLMs to break down complex queries step-by-step for better reasoning, improving their effectiveness across a range of tasks. <br> <br>
            </span>
                </div>
            </div>

        </div>
    </div>
</section>

<!--Model-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span class="dvima">Transforming Conversational AI</span></h2>
            <span style="font-size: 125%">
                We defined a Conversational Agent as an LLM-based system designed to perform multi-turn interactions with users, by integrating reasoning and planning capabilities with action execution, following the predefined instructions. <br> <br>
                While LLMs excel in language tasks, they often lack real-time information retrieval and user-specific action capabilities. Tool-enabled agents can now make API calls or interact with external systems to fetch real-time data, like checking the weather or booking a reservation. These agents can manage real-world operations more effectively, providing users with more practical and responsive assistance. <br> <br>
                Some applications require more than just responses—they require action-based reasoning, like planning a series of steps. The ReAct framework enables LLMs to combine reasoning with actions, making them capable of following a more analytical process. Meanwhile, systems like Reflexion encourage LLMs to self-reflect, learning from past errors to improve future decisions. <br> <br>
                Multi-agent frameworks can coordinate specialized agents to handle complex tasks. For example, a travel planning system may employ a “concierge” AI to manage and delegate tasks among specialized agents, such as flight bookings, hotel reservations, or restaurant searches, improving both accuracy and efficiency in handling intricate, multi-faceted queries. <br> <br>
            </span>
                </div>
            </div>

        </div>
    </div>
</section>

<!--Model-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span class="dvima">Challenges and Future Directions</span></h2>
            <span style="font-size: 125%">
                Though Conversational AI Agents have made remarkable progress, challenges remain. Ensuring controllability, managing context, and avoiding hallucinations (where the agent generates inaccurate responses) are key areas for improvement. Agents also need personalized interactions, where memory-based systems track user preferences for more tailored responses, enhancing trust and user satisfaction.<br> <br>
                Looking forward, the focus is on evolving these systems to improve adaptability, multi-step planning, and interaction clarity. Combining human feedback, policy alignment, and interactivity will help Conversational AI Agents perform better in dynamic, real-world applications and offer a more natural, personalized user experience. <br> <br>
            </span>
                </div>
            </div>

        </div>
    </div>
</section>



<section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
        @misc{acikgoz2024convai,
            title={The Rise of Conversational AI Agents with Large Language Models}, 
            author={Emre Can Acikgoz and Dilek Hakkani-Tur and Gokhan Tur},
            year={2024},
            primaryClass={cs.CL}
        }
        </code></pre>
    </div>
</section>




<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column">
                <div class="content has-text-centered">
                    <p>
                        Website template borrowed from <a
                            href="https://vimalabs.github.io/">VIMA</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
